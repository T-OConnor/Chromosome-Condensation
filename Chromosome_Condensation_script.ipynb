{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ede730e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Starting processing for 1000 beads...\n",
      "Reading replicate 1: D:\\Project\\LE\\Beads\\1000\\replicate_1\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 1 (30402 timepoints)\n",
      "‚è±Ô∏è Replicate 1 completed in 1457.08 sec\n",
      "Reading replicate 2: D:\\Project\\LE\\Beads\\1000\\replicate_2\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 2 (27371 timepoints)\n",
      "‚è±Ô∏è Replicate 2 completed in 965.27 sec\n",
      "Reading replicate 3: D:\\Project\\LE\\Beads\\1000\\replicate_3\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 3 (26563 timepoints)\n",
      "‚è±Ô∏è Replicate 3 completed in 973.27 sec\n",
      "Reading replicate 4: D:\\Project\\LE\\Beads\\1000\\replicate_4\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 4 (30402 timepoints)\n",
      "‚è±Ô∏è Replicate 4 completed in 1186.06 sec\n",
      "Reading replicate 5: D:\\Project\\LE\\Beads\\1000\\replicate_5\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 5 (30402 timepoints)\n",
      "‚è±Ô∏è Replicate 5 completed in 1118.00 sec\n",
      "Reading replicate 6: D:\\Project\\LE\\Beads\\1000\\replicate_6\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 6 (21614 timepoints)\n",
      "‚è±Ô∏è Replicate 6 completed in 602.74 sec\n",
      "Reading replicate 7: D:\\Project\\LE\\Beads\\1000\\replicate_7\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 7 (30402 timepoints)\n",
      "‚è±Ô∏è Replicate 7 completed in 1213.55 sec\n",
      "Reading replicate 8: D:\\Project\\LE\\Beads\\1000\\replicate_8\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 8 (30402 timepoints)\n",
      "‚è±Ô∏è Replicate 8 completed in 1185.62 sec\n",
      "Reading replicate 9: D:\\Project\\LE\\Beads\\1000\\replicate_9\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 9 (24947 timepoints)\n",
      "‚è±Ô∏è Replicate 9 completed in 821.74 sec\n",
      "Reading replicate 10: D:\\Project\\LE\\Beads\\1000\\replicate_10\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 10 (30402 timepoints)\n",
      "‚è±Ô∏è Replicate 10 completed in 1200.04 sec\n",
      "üìä Fitting and plotting: length dimension for 1000 beads\n",
      "‚ùå Error in fitting/plotting for length, 1000 beads: all input arrays must have the same shape\n",
      "üìä Fitting and plotting: width dimension for 1000 beads\n",
      "‚ùå Error in fitting/plotting for width, 1000 beads: all input arrays must have the same shape\n",
      "üìä Fitting and plotting: depth dimension for 1000 beads\n",
      "‚ùå Error in fitting/plotting for depth, 1000 beads: all input arrays must have the same shape\n",
      "‚úÖ Completed all processing for 1000 beads in 10742.12 sec\n",
      "\n",
      "üîÑ Starting processing for 250 beads...\n",
      "Reading replicate 1: D:\\Project\\LE\\Beads\\250\\replicate_1\\_msd_bead_coord.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15196/45310359.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"‚úÖ Completed all processing for {bead_count} beads in {time.time() - bead_start:.2f} sec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15196/45310359.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mrep_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_replicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrep_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15196/45310359.py\u001b[0m in \u001b[0;36mprocess_replicate\u001b[1;34m(file_path, rep_idx)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtime_points\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0mcoords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time(s)'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x(nm)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y(nm)'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'z(nm)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m             \u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_average_dimensions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mdims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3447\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3448\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3449\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3451\u001b[0m         \u001b[1;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3501\u001b[0m         \u001b[1;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3502\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3503\u001b[1;33m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3504\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Here is some of the code I used for my final year Chromsome-Condensation project - Taylor-Jai O'Connor ###\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Initial configuration for lengths per bead count\n",
    "initial_lengths = {\n",
    "    250: 1906,\n",
    "    500: 2515,\n",
    "    1000: 3318,\n",
    "}\n",
    "\n",
    "# Initial guesses for xeqm and tau\n",
    "initial_guesses = {\n",
    "    250: {'length': (1000, 100), 'width': (500, 10), 'depth': (270, 40)},\n",
    "    500: {'length': (1800, 575), 'width': (750, 40), 'depth': (400, 20)},\n",
    "    1000: {'length': (1800, 1200), 'width': (1000, 400), 'depth': (600, 50)},\n",
    "}\n",
    "\n",
    "def exp_decay(t, xeq, tau, x0):\n",
    "    return xeq + (x0 - xeq) * np.exp(-t / tau)\n",
    "\n",
    "def compute_average_dimensions(coords):\n",
    "    cov_matrix = np.cov(coords.T)\n",
    "    eigenvalues = np.linalg.eigvalsh(cov_matrix)\n",
    "    eigenvalues = np.sort(eigenvalues)[::-1]\n",
    "    return 2 * np.sqrt(eigenvalues)  # length, width, depth, in descending order\n",
    "\n",
    "def fit_decay(time, values, bead_count, dimension):\n",
    "    x0 = initial_lengths[bead_count]\n",
    "    xeq_guess, tau_guess = initial_guesses[bead_count][dimension]\n",
    "\n",
    "    def decay_model(t, xeq, tau):\n",
    "        return exp_decay(t, xeq, tau, x0)\n",
    "\n",
    "    try:\n",
    "        popt, _ = curve_fit(\n",
    "            decay_model, np.array(time), np.array(values),\n",
    "            p0=[xeq_guess, tau_guess],\n",
    "            bounds=([0, 1], [x0, np.inf]),\n",
    "            maxfev=20000\n",
    "        )\n",
    "        return x0, popt[0], popt[1]\n",
    "    except Exception as e:\n",
    "        print(f\"Fit error for {dimension}, {bead_count} beads: {e}\")\n",
    "        return x0, np.nan, np.nan\n",
    "\n",
    "def process_replicate(file_path, rep_idx):\n",
    "    dims = {}\n",
    "    try:\n",
    "        print(f\"Reading replicate {rep_idx}: {file_path}\")\n",
    "        df = pd.read_csv(file_path, delim_whitespace=True, usecols=['time(s)', 'Type(bead)', 'x(nm)', 'y(nm)', 'z(nm)'])\n",
    "        df = df[df['Type(bead)'] == 'N']\n",
    "        time_points = sorted(df['time(s)'].unique())\n",
    "\n",
    "        dims['time'] = []\n",
    "        dims['length'] = []\n",
    "        dims['width'] = []\n",
    "        dims['depth'] = []\n",
    "\n",
    "        for t in time_points:\n",
    "            coords = df[df['time(s)'] == t][['x(nm)', 'y(nm)', 'z(nm)']].values\n",
    "            length, width, depth = compute_average_dimensions(coords)\n",
    "            dims['time'].append(t)\n",
    "            dims['length'].append(length)\n",
    "            dims['width'].append(width)\n",
    "            dims['depth'].append(depth)\n",
    "\n",
    "        print(f\"Finished processing replicate {rep_idx} ({len(time_points)} timepoints)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "    return pd.DataFrame(dims)\n",
    "\n",
    "def plot_fitted_curve(time, values, xeq, tau, bead_count, dimension, output_path):\n",
    "    x0 = initial_lengths[bead_count]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(time, values, label='Mean Data')\n",
    "    if not np.isnan(xeq) and not np.isnan(tau):\n",
    "        fitted = exp_decay(np.array(time), xeq, tau, x0)\n",
    "        plt.plot(time, fitted, '--', label=f'Exp Fit\\nxeq={xeq:.1f}, tau={tau:.1f}')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel(f'{dimension.capitalize()} (nm)')\n",
    "    plt.title(f'Average {dimension.capitalize()} vs Time\\n{bead_count} Beads')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(f\" Plot saved to: {output_path}\")\n",
    "\n",
    "def main():\n",
    "    base_dir = r\"\"\n",
    "    output_dir = r\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    bead_counts = [1000, 250, 500]  # Start with 1000, get the largest files out of the way first\n",
    "    dimensions = ['length', 'width', 'depth']\n",
    "\n",
    "    for bead_count in bead_counts:\n",
    "        print(f\"\\n Starting processing for {bead_count} beads...\")\n",
    "        bead_start = time.time()\n",
    "\n",
    "        replicate_paths = [\n",
    "            os.path.join(base_dir, str(bead_count), f'replicate_{i}', '_msd_bead_coord.txt')\n",
    "            for i in range(1, 11)\n",
    "        ]\n",
    "\n",
    "        time_list = None\n",
    "        dim_accum = {dim: [] for dim in dimensions}\n",
    "\n",
    "        for rep_idx, file_path in enumerate(replicate_paths, 1):\n",
    "            if not os.path.isfile(file_path):\n",
    "                print(f\"Missing replicate {rep_idx}: {file_path}\")\n",
    "                continue\n",
    "\n",
    "            rep_start = time.time()\n",
    "            df = process_replicate(file_path, rep_idx)\n",
    "            if df.empty:\n",
    "                continue\n",
    "\n",
    "            if time_list is None:\n",
    "                time_list = df['time'].values\n",
    "\n",
    "            for dim in dimensions:\n",
    "                dim_accum[dim].append(df[dim].values)\n",
    "\n",
    "            print(f\"Replicate {rep_idx} completed in {time.time() - rep_start:.2f} sec\")\n",
    "\n",
    "        if time_list is None:\n",
    "            print(f\"No usable data for {bead_count} beads. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        time_array = np.array(time_list)\n",
    "        for dim in dimensions:\n",
    "            print(f\"Plotting: {dim} dimension for {bead_count} beads\")\n",
    "            try:\n",
    "                dim_matrix = np.array(dim_accum[dim], dtype=object)\n",
    "                dim_matrix = np.stack(dim_matrix)  # Truncated timepoints, make sure dimensions of all matrices are the same for easy plotting\n",
    "                mean_values = np.mean(dim_matrix, axis=0)\n",
    "                x0, xeq, tau = fit_decay(time_array, mean_values, bead_count, dim)\n",
    "\n",
    "                plot_path = os.path.join(output_dir, f'{bead_count}_{dim}_fit.png')\n",
    "                plot_fitted_curve(time_array, mean_values, xeq, tau, bead_count, dim, plot_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in plotting for {dim}, {bead_count} beads: {e}\")\n",
    "\n",
    "        print(f\"Completed processing for {bead_count} beads in {time.time() - bead_start:.2f} sec\")\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5063ab8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Reprocessing 1000 beads using truncated timepoints...\n",
      "Reading replicate 1: D:\\Project\\LE\\Beads\\1000\\replicate_1\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 1 (30402 timepoints)\n",
      "Reading replicate 2: D:\\Project\\LE\\Beads\\1000\\replicate_2\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 2 (27371 timepoints)\n",
      "Reading replicate 3: D:\\Project\\LE\\Beads\\1000\\replicate_3\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 3 (26563 timepoints)\n",
      "Reading replicate 4: D:\\Project\\LE\\Beads\\1000\\replicate_4\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 4 (30402 timepoints)\n",
      "Reading replicate 5: D:\\Project\\LE\\Beads\\1000\\replicate_5\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 5 (30402 timepoints)\n",
      "Reading replicate 6: D:\\Project\\LE\\Beads\\1000\\replicate_6\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 6 (21614 timepoints)\n",
      "Reading replicate 7: D:\\Project\\LE\\Beads\\1000\\replicate_7\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 7 (30402 timepoints)\n",
      "Reading replicate 8: D:\\Project\\LE\\Beads\\1000\\replicate_8\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 8 (30402 timepoints)\n",
      "Reading replicate 9: D:\\Project\\LE\\Beads\\1000\\replicate_9\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 9 (24947 timepoints)\n",
      "Reading replicate 10: D:\\Project\\LE\\Beads\\1000\\replicate_10\\_msd_bead_coord.txt\n",
      "‚úÖ Finished processing replicate 10 (30402 timepoints)\n",
      "‚úÇÔ∏è Truncating all replicate data to 21614 timepoints...\n",
      "üìä Fitting and plotting: length dimension for 1000 beads\n",
      "üìà Saved plot: D:\\Project\\LE_beads\\1000_length_fit_truncated.png\n",
      "‚úÖ Saved plot: D:\\Project\\LE_beads\\1000_length_fit_truncated.png\n",
      "üìä Fitting and plotting: width dimension for 1000 beads\n",
      "üìà Saved plot: D:\\Project\\LE_beads\\1000_width_fit_truncated.png\n",
      "‚úÖ Saved plot: D:\\Project\\LE_beads\\1000_width_fit_truncated.png\n",
      "üìä Fitting and plotting: depth dimension for 1000 beads\n",
      "üìà Saved plot: D:\\Project\\LE_beads\\1000_depth_fit_truncated.png\n",
      "‚úÖ Saved plot: D:\\Project\\LE_beads\\1000_depth_fit_truncated.png\n"
     ]
    }
   ],
   "source": [
    "# üîÅ Truncate 1000 bead replicate data to shortest common time length and reprocess\n",
    "\n",
    "bead_count = 1000\n",
    "dimensions = ['length', 'width', 'depth']\n",
    "\n",
    "output_dir = r\"D:\\Project\\LE_beads\"\n",
    "base_dir = r\"D:\\Project\\LE\\Beads\"  # Make sure this matches your actual path\n",
    "\n",
    "print(f\"\\nüîß Reprocessing {bead_count} beads using truncated timepoints...\")\n",
    "\n",
    "replicate_paths = [\n",
    "    os.path.join(base_dir, str(bead_count), f'replicate_{i}', '_msd_bead_coord.txt')\n",
    "    for i in range(1, 11)\n",
    "]\n",
    "\n",
    "dim_accum = {dim: [] for dim in dimensions}\n",
    "lengths = []\n",
    "time_ref = None  # To get truncated time axis\n",
    "\n",
    "for rep_idx, file_path in enumerate(replicate_paths, 1):\n",
    "    if not os.path.isfile(file_path):\n",
    "        print(f\"‚ùå Missing file: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    df = process_replicate(file_path, rep_idx)\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è Skipping empty replicate {rep_idx}\")\n",
    "        continue\n",
    "\n",
    "    lengths.append(len(df['time']))\n",
    "\n",
    "    if time_ref is None or len(df['time']) < len(time_ref):\n",
    "        time_ref = df['time'].values  # Keep shortest\n",
    "\n",
    "    for dim in dimensions:\n",
    "        dim_accum[dim].append(df[dim].values)\n",
    "\n",
    "# Truncate to minimum time length\n",
    "min_length = min(lengths)\n",
    "print(f\"‚úÇÔ∏è Truncating all replicate data to {min_length} timepoints...\")\n",
    "\n",
    "truncated_data = {\n",
    "    dim: [rep[:min_length] for rep in dim_accum[dim]]\n",
    "    for dim in dimensions\n",
    "}\n",
    "time_array = time_ref[:min_length]\n",
    "\n",
    "# Fit and plot again\n",
    "for dim in dimensions:\n",
    "    print(f\"üìä Fitting and plotting: {dim} dimension for {bead_count} beads\")\n",
    "    try:\n",
    "        dim_matrix = np.array(truncated_data[dim])\n",
    "        mean_values = np.mean(dim_matrix, axis=0)\n",
    "        x0, xeq, tau = fit_decay(time_array, mean_values, bead_count, dim)\n",
    "\n",
    "        plot_path = os.path.join(output_dir, f'{bead_count}_{dim}_fit_truncated.png')\n",
    "        plot_fitted_curve(time_array, mean_values, xeq, tau, bead_count, dim, plot_path)\n",
    "        print(f\"‚úÖ Saved plot: {plot_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in fitting/plotting for {dim}, {bead_count} beads: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7af439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
